{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Conversational AI ChatBot](https://www.kaggle.com/rajkumarl/conversational-ai-chatbot)\n\n### Intelligent ChatBot built with Microsoft's DialoGPT transformer to make conversations with human users! \n\n![cover image](https://raw.githubusercontent.com/RajkumarGalaxy/dataset/master/Images/robo%20girl.jpg)\n> ##### [Image by Andy Kelly](https://unsplash.com/@askkell) ","metadata":{}},{"cell_type":"markdown","source":"### What is a chatbot?\n\n>##### A ChatBot is a kind of virtual assistant that can build conversations with human users! A *Chat*ting Ro*bot*. Building a chatbot is one of the popular tasks in Natural Language Processing.\n\n### Are all chatbots the same?\n>##### Chatbots fall under three common categories:\n>##### 1. Rule-based chatbots\n>##### 2. Retrieval-based chatbots\n>##### 3. Intelligent chatbots\n\n### Rule-based chatbots\n>##### These bots respond to users' inputs based on certain pre-specified rules. For instance, these rules can be defined as if-elif-else statements. While writing rules for these chatbots, it is important to expect all possible user inputs, else the bot may fail to answer properly. Hence, rule-based chatbots do not possess any cognitive skills.\n\n### Retrieval-based chatbots\n>##### These bots respond to users' inputs by retrieving the most relevant information from the given text document. The most relevant information can be determined by Natural Language Processing with a scoring system such as cosine-similarity-score. Though these bots use NLP to do conversations, they lack cognitive skills to match a real human chatting companion.\n\n### Intelligent AI chatbots\n>##### These bots respond to users' inputs after understanding the inputs, as humans do. These bots are trained with a Machine Learning Model on a large training dataset of human conversations. These bots are cognitive to match a human in conversing. Amazon's Alexa, Apple's Siri fall under this category. Further, most of these bots can make conversations based on the preceding chat texts.\n\n### In this Article?\n>##### This article describes building an intelligent AI chatbot based on the famous transformer architecture - Microsoft's DialoGPT. According to [Hugging Face's model card](https://huggingface.co/microsoft/DialoGPT-medium), DialoGPT is a State-Of-The-Art large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread.\n","metadata":{}},{"cell_type":"markdown","source":"# Let's Python\n\n##### Import necessary libraries and frameworks","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport time\nimport os\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-27T03:20:21.344611Z","iopub.execute_input":"2021-12-27T03:20:21.345452Z","iopub.status.idle":"2021-12-27T03:20:29.382776Z","shell.execute_reply.started":"2021-12-27T03:20:21.345354Z","shell.execute_reply":"2021-12-27T03:20:29.382084Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Download Microsoft's DialoGPT model and tokenizer\n\n##### The Hugging Face checkpoint for the model and its tokenizer is `\"microsoft/DialoGPT-medium\"`","metadata":{}},{"cell_type":"code","source":"# checkpoint \ncheckpoint = \"microsoft/DialoGPT-medium\"\n# download and cache tokenizer\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n# download and cache pre-trained model\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:20:29.384121Z","iopub.execute_input":"2021-12-27T03:20:29.384850Z","iopub.status.idle":"2021-12-27T03:21:05.195561Z","shell.execute_reply.started":"2021-12-27T03:20:29.384807Z","shell.execute_reply":"2021-12-27T03:21:05.194949Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"110705f41ead4dfdbbfe7dbfc0159f8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8796167b3e9f405eb1fa0d0c890c2251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa2be202cbf4d76bc78dbc5f40d0fd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684ea2e989c1495dbcea3f73103a0b95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/823M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a18d2add96044e52ba4b8005e0973e64"}},"metadata":{}}]},{"cell_type":"markdown","source":"# A ChatBot class","metadata":{}},{"cell_type":"code","source":"# Build a ChatBot class with all necessary modules to make a complete conversation\nclass ChatBot():\n    # initialize\n    def __init__(self):\n        # once chat starts, the history will be stored for chat continuity\n        self.chat_history_ids = None\n        # make input ids global to use them anywhere within the object\n        self.bot_input_ids = None\n        # a flag to check whether to end the conversation\n        self.end_chat = False\n        # greet while starting\n        self.welcome()\n        \n    def welcome(self):\n        print(\"Initializing ChatBot ...\")\n        # some time to get user ready\n        time.sleep(2)\n        print('Type \"bye\" or \"quit\" or \"exit\" to end chat \\n')\n        # give time to read what has been printed\n        time.sleep(3)\n        # Greet and introduce\n        greeting = np.random.choice([\n            \"Welcome, I am ChatBot, here for your kind service\",\n            \"Hey, Great day! I am your virtual assistant\",\n            \"Hello, it's my pleasure meeting you\",\n            \"Hi, I am a ChatBot. Let's chat!\"\n        ])\n        print(\"ChatBot >>  \" + greeting)\n        \n    def user_input(self):\n        # receive input from user\n        text = input(\"User    >> \")\n        # end conversation if user wishes so\n        if text.lower().strip() in ['bye', 'quit', 'exit']:\n            # turn flag on \n            self.end_chat=True\n            # a closing comment\n            print('ChatBot >>  See you soon! Bye!')\n            time.sleep(1)\n            print('\\nQuitting ChatBot ...')\n        else:\n            # continue chat, preprocess input text\n            # encode the new user input, add the eos_token and return a tensor in Pytorch\n            self.new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, \\\n                                                       return_tensors='pt')\n\n    def bot_response(self):\n        # append the new user input tokens to the chat history\n        # if chat has already begun\n        if self.chat_history_ids is not None:\n            self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1) \n        else:\n            # if first entry, initialize bot_input_ids\n            self.bot_input_ids = self.new_user_input_ids\n        \n        # define the new chat_history_ids based on the preceding chats\n        # generated a response while limiting the total chat history to 1000 tokens, \n        self.chat_history_ids = model.generate(self.bot_input_ids, max_length=1000, \\\n                                               pad_token_id=tokenizer.eos_token_id)\n            \n        # last ouput tokens from bot\n        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], \\\n                               skip_special_tokens=True)\n        # in case, bot fails to answer\n        if response == \"\":\n            response = self.random_response()\n        # print bot response\n        print('ChatBot >>  '+ response)\n        \n    # in case there is no response from model\n    def random_response(self):\n        i = -1\n        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n                               skip_special_tokens=True)\n        # iterate over history backwards to find the last token\n        while response == '':\n            i = i-1\n            response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0], \\\n                               skip_special_tokens=True)\n        # if it is a question, answer suitably\n        if response.strip() == '?':\n            reply = np.random.choice([\"I don't know\", \n                                     \"I am not sure\"])\n        # not a question? answer suitably\n        else:\n            reply = np.random.choice([\"Great\", \n                                      \"Fine. What's up?\", \n                                      \"Okay\"\n                                     ])\n        return reply","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:21:05.197163Z","iopub.execute_input":"2021-12-27T03:21:05.197911Z","iopub.status.idle":"2021-12-27T03:21:05.215424Z","shell.execute_reply.started":"2021-12-27T03:21:05.197861Z","shell.execute_reply":"2021-12-27T03:21:05.214499Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Happy Chatting!","metadata":{}},{"cell_type":"code","source":"# build a ChatBot object\nbot = ChatBot()\n# start chatting\nwhile True:\n    # receive user input\n    bot.user_input()\n    # check whether to end chat\n    if bot.end_chat:\n        break\n    # output bot response\n    bot.bot_response()    ","metadata":{"execution":{"iopub.status.busy":"2021-12-27T03:21:05.217133Z","iopub.execute_input":"2021-12-27T03:21:05.217343Z","iopub.status.idle":"2021-12-27T03:31:17.740707Z","shell.execute_reply.started":"2021-12-27T03:21:05.217317Z","shell.execute_reply":"2021-12-27T03:31:17.739565Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Initializing ChatBot ...\nType \"bye\" or \"quit\" or \"exit\" to end chat \n\nChatBot >>  Welcome, I am ChatBot, here for your kind service\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Hi. How are you?\n"},{"name":"stdout","text":"ChatBot >>  I'm good, how are you?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  I'm fine. Do you cook?\n"},{"name":"stdout","text":"ChatBot >>  I do.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  What is your favourite recipe?\n"},{"name":"stdout","text":"ChatBot >>  I don't really cook.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  No problem. What is your favourite food?\n"},{"name":"stdout","text":"ChatBot >>  I don't really eat food.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  I know. I like sea food a lot.\n"},{"name":"stdout","text":"ChatBot >>  I like that.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  I have coffee often. How about you?\n"},{"name":"stdout","text":"ChatBot >>  I like coffee.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Do you take coffee with milk and sugar?\n"},{"name":"stdout","text":"ChatBot >>  I don't drink coffee.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Oh, you like it but don't drink. I understand.\n"},{"name":"stdout","text":"ChatBot >>  I don't drink coffee\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  Shall we have dinner tonight?\n"},{"name":"stdout","text":"ChatBot >>  Fine. What's up?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  I will book a table and inform you. Be ready.\n"},{"name":"stdout","text":"ChatBot >>  Okay\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User    >>  bye\n"},{"name":"stdout","text":"ChatBot >>  See you soon! Bye!\n\nQuitting ChatBot ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Some sample chats by this ChatBot\n\n![chat1](https://raw.githubusercontent.com/RajkumarGalaxy/Conversational-AI-ChatBot/main/chatbot_chats_1.jpg)\n\n![chat2](https://raw.githubusercontent.com/RajkumarGalaxy/Conversational-AI-ChatBot/main/chatbot_chats_2.jpg)","metadata":{}},{"cell_type":"markdown","source":"##### Thank you for your valuable time!\nFind this notebook on Kaggle here: https://www.kaggle.com/rajkumarl/conversational-ai-chatbot","metadata":{}}]}